---
layout: post
title:  "2021_1"
---


| Header One     | Header Two     | |
| :------------- | :------------- |:------ |
|  1  | train/eval BC13_GST_fbank <br>        |  <br>  |
|  18  | modify and start train emocontrlTTS<br>        |  NO  |
|  19  | modify and start train emocontrlTTS<br>        |  NO  |
|  20  | modify and start train emocontrlTTS<br>        |  NO  |


2/3:
1. Vocoder - Gan implement or grifflim
  - grifflim problem
  - n_fft, hop_length, window_length, n_mels
  - iven_mel_basis * (mel_basis * mags) != mags ??
    - np.linalg.pinv(mel_basis) psuedo inverse matrix is problem?
    - mels -> mags is lossy Process, and make sure frequency warping is similar with mels extracting, otherwise disharmonic audio



2. Implement Category VAE
  - Dim(z) = base_dim(z) * Categories ? why?
  - no Linear model for mu, theta ?

![1](img/cvae_1.jpg)

2/5
- Learn to see spectrogram
  - Pitch rise/drop ?
  -
- See the every detail in each stage to check the training Process
  - emo VS emo_feats!


2/9

decode/syn in espnet1
1. decode and synthesis step

decode/syn in espnet2
1. Dot(invers_mel_basis, mags) directly in logmel2linear of Text2speech.
2. Vocoder by parallel_wavegan

  by np.linalg.pinv(mel_basis)


Other
3.
